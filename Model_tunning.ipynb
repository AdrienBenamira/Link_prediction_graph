{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will report our experiments about the impact of various classifiers (e.g., SVM, Random Forest, Boosting, logistic regression...) and for each classifier, explain the procedure that was followed to tackle parameter tuning and prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/benamira/19793564030D4273/MCsBackup/3A/OMA/NGSA/Assigment/kaggle_competition/utils\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import Config\n",
    "from utils.extract_features import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "config = Config(\"config/\")\n",
    "\n",
    "E_F = features_dataset(config.preprocess_all)\n",
    "if config.preprocess_all:\n",
    "    E_F.prepocess_data()\n",
    "train_features, training_labels, test_features = E_F.load_features_all()\n",
    "m = train_features.mean(axis=0)\n",
    "std = train_features.std(axis=0)\n",
    "if config.norm:\n",
    "    train_features = (train_features - m) / std\n",
    "    test_features = (test_features - m) / std\n",
    "\n",
    "a_tester = config.features_a_tester\n",
    "train_features = train_features[:, a_tester]\n",
    "test_features = test_features[:, a_tester]\n",
    "\n",
    "kf = StratifiedKFold(n_splits=config.num_split_cross_val, shuffle=True)\n",
    "\n",
    "train_features = pd.DataFrame(train_features)\n",
    "training_labels = pd.DataFrame(training_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "def train_predict_save(model, tr, val, y_tr, y_val):\n",
    "    fscore_t = f1_score(y_tr,\n",
    "                        model.predict(tr))\n",
    "    fscore_v = f1_score(y_val,\n",
    "                        model.predict(val))\n",
    "    #print(\" model: F1 score - Training %.3f - Validation %.3f\" % (fscore_t, fscore_v))    \n",
    "    return(fscore_t, fscore_v)\n",
    "\n",
    "def eval_model(model, train_features, training_labels, idx):\n",
    "    predicts_t = []\n",
    "    predicts_v = []\n",
    "    for train_index, test_index in kf.split(train_features, training_labels):\n",
    "        n = int(0.1*(len(train_index)+len(test_index)))\n",
    "        random.shuffle(test_index)\n",
    "        test_index_new = test_index[:n]\n",
    "        train_index_new = np.union1d(test_index[n:], train_index)\n",
    "\n",
    "        X_train, X_val = train_features.iloc[train_index_new], train_features.iloc[test_index_new]\n",
    "        y_train, y_val = training_labels.iloc[train_index_new], training_labels.iloc[test_index_new]\n",
    "        \n",
    "        if idx == 0:\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "                    early_stopping_rounds=50, verbose=None)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        fscore_t, fscore_v = train_predict_save(model, X_train, X_val, y_train, y_val)\n",
    "        predicts_t.append(fscore_t)\n",
    "        predicts_v.append(fscore_v)\n",
    "        \n",
    "    return(predicts_t, predicts_v)\n",
    "\n",
    "\n",
    "modelGB = lgb.LGBMClassifier(objective='binary', reg_lambda=config.reg_lambda_gb,\n",
    "                           n_estimators=config.n_estimator_GB  )\n",
    "modelRF = RandomForestClassifier(n_estimators=500)\n",
    "modelSVM = svm.LinearSVC()\n",
    "modelL = LogisticRegression()\n",
    "\n",
    "res_t = {}\n",
    "res_v = {}\n",
    "for idx, model in enumerate([modelGB, modelRF, modelSVM, modelL]):\n",
    "    print(idx)\n",
    "    (fscore_t, fscore_v) = eval_model(model, train_features, training_labels, idx)\n",
    "    res_t[idx] = fscore_t\n",
    "    res_v[idx] = fscore_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'penalty': ['l2','l1'],\n",
    "    'dual': [True, False],\n",
    "    'tol': [1e-4,1e-3,1e-5],\n",
    "    'C': [0.1, 1, 10],\n",
    "}\n",
    "# Create a base model\n",
    "rf = svm.LinearSVC()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                          cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_features, training_labels);\n",
    "grid_search.best_params_\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base model\n",
    "rf = LogisticRegression()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                          cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_features, training_labels);\n",
    "grid_search.best_params_\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000]\n",
    "}\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                          cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_features, training_labels);\n",
    "grid_search.best_params_\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
